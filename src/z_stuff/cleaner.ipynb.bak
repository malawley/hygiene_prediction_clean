{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198fb16c-5588-4b2f-9b7e-911232ece84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google-cloud-storage: The official GCS client library for Python\n",
    "# polars: The high-performance DataFrame library (your main tool for cleaning)\n",
    "# %pip install --quiet google-cloud-storage polars\n",
    "# %pip install --quiet rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "452761e0-f6d4-417b-98bd-eeaba9128052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import polars as pl\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "import logging\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Show all rows (or set to 200 or 1000 if needed)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Prevent column content from being truncated\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Don't wrap output across lines\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/malaw/OneDrive/Documents/MSDS/hygiene-prediction-434-48fe02c5707d.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7dfe57-1e00-41de-a17c-79f0d0a1193a",
   "metadata": {},
   "source": [
    "#### Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04c144d-14df-4c69-9d84-8ee48394df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up logger once, at the top of your notebook or script\n",
    "logger = logging.getLogger(\"cleaner\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.FileHandler(\"cleaner.log\", mode=\"a\")\n",
    "formatter = logging.Formatter(\"[%(asctime)s] %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16368576-fa54-45eb-9969-11378df65c4b",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165274fa-ebfb-4672-8b85-9363b7fc964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_info(df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Prints shape, schema, and full null count list for a Polars DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“ Shape:\", df.shape)\n",
    "\n",
    "    print(\"\\nðŸ“‹ Schema:\")\n",
    "    for col, dtype in df.schema.items():\n",
    "        print(f\" - {col}: {dtype}\")\n",
    "\n",
    "    print()  # Add spacing\n",
    "    print_null_counts(df)\n",
    "\n",
    "\n",
    "def print_null_counts(df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Prints null counts for each column as a clean list.\n",
    "    \"\"\"\n",
    "    print(\"â“ Null counts per column:\")\n",
    "    null_df = df.null_count()\n",
    "    null_dict = null_df.row(0)  # row 0 has all counts\n",
    "    for col, count in zip(null_df.columns, null_dict):\n",
    "        print(f\" - {col}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16d8285-ec16-441d-9139-d33c6d4a9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaner environment initialized.\n"
     ]
    }
   ],
   "source": [
    "# Setup to access bucket \n",
    "\n",
    "BUCKET_NAME = \"raw-inspection-data-434\"\n",
    "DATE = \"2025-03-30\"\n",
    "RAW_PREFIX = f\"raw-data/{DATE}/\"\n",
    "CLEAN_PREFIX = f\"clean-data/{DATE}/\"\n",
    "MANIFEST_PATH = f\"{RAW_PREFIX}_manifest.json\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "print(\"âœ… Cleaner environment initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46194f03-6c47-4c12-9696-945d31263137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found manifest with 117 files.\n"
     ]
    }
   ],
   "source": [
    "# Load the manifest from GCS\n",
    "blob = bucket.blob(MANIFEST_PATH)\n",
    "manifest_data = blob.download_as_text()\n",
    "manifest = json.loads(manifest_data)\n",
    "\n",
    "# Validate manifest\n",
    "if not manifest.get(\"upload_complete\", False):\n",
    "    raise ValueError(\"Manifest is not marked as complete.\")\n",
    "\n",
    "files_to_process = manifest[\"files\"]\n",
    "print(f\"âœ… Found manifest with {len(files_to_process)} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba597b74-4706-4542-9044-cfa0b8ccc5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Sample combined shape: (20000, 17)\n",
      "ðŸ“ Shape: (20000, 17)\n",
      "\n",
      "ðŸ“‹ Schema:\n",
      " - inspection_id: String\n",
      " - dba_name: String\n",
      " - aka_name: String\n",
      " - license_: String\n",
      " - facility_type: String\n",
      " - risk: String\n",
      " - address: String\n",
      " - city: String\n",
      " - state: String\n",
      " - zip: String\n",
      " - inspection_date: String\n",
      " - inspection_type: String\n",
      " - results: String\n",
      " - violations: String\n",
      " - latitude: String\n",
      " - longitude: String\n",
      " - location: Struct({'type': String, 'coordinates': List(Float64)})\n",
      "\n",
      "â“ Null counts per column:\n",
      " - inspection_id: 0\n",
      " - dba_name: 0\n",
      " - aka_name: 27\n",
      " - license_: 0\n",
      " - facility_type: 118\n",
      " - risk: 6\n",
      " - address: 0\n",
      " - city: 25\n",
      " - state: 5\n",
      " - zip: 0\n",
      " - inspection_date: 0\n",
      " - inspection_type: 0\n",
      " - results: 0\n",
      " - violations: 6443\n",
      " - latitude: 75\n",
      " - longitude: 75\n",
      " - location: 75\n"
     ]
    }
   ],
   "source": [
    "# Open a large sample to perfect cleaning, then return to file by file.\n",
    "\n",
    "sample_files = files_to_process[:20]  # Adjust as needed\n",
    "frames = []\n",
    "\n",
    "for filename in sample_files:\n",
    "    blob = bucket.blob(f\"{RAW_PREFIX}{filename}\")\n",
    "    raw_bytes = blob.download_as_bytes()\n",
    "    df = pl.read_json(BytesIO(raw_bytes))\n",
    "    frames.append(df)\n",
    "\n",
    "df = pl.concat(frames)\n",
    "print(f\"ðŸ” Sample combined shape: {df.shape}\")\n",
    "\n",
    "df.schema, \n",
    "polars_info(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7ea47d-d9ba-44e8-9940-43d87336181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is cell by cell\n",
    "\n",
    "# # Step 1: Choose first file\n",
    "# first_file = files_to_process[0]\n",
    "# raw_path = f\"{RAW_PREFIX}{first_file}\"\n",
    "\n",
    "# # Step 2: Download from GCS\n",
    "# blob = bucket.blob(raw_path)\n",
    "# raw_bytes = blob.download_as_bytes()\n",
    "\n",
    "# # Step 3: Load into Polars\n",
    "# df = pl.read_json(BytesIO(raw_bytes))\n",
    "\n",
    "# # Step 4: Show schema and head\n",
    "# print(\"âœ… File loaded into Polars:\")\n",
    "# df.schema, \n",
    "# polars_info(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ef345c-6f38-432d-8c1f-e903f1794d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_1_drop(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 1 cleaner function with logging:\n",
    "    - Drops unused or redundant columns\n",
    "    - Drops rows with nulls in any column EXCEPT 'violations'\n",
    "    - Keeps rows with violations = null only if result is 'Pass' or 'Pass w/ Conditions'\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): Raw inspection data\n",
    "        logger (optional): Python logger object for file logging\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Cleaned DataFrame with selected columns only\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            logger.info(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    original_rows = df.height\n",
    "    log(f\"Starting with {original_rows} rows\")\n",
    "\n",
    "    columns_to_drop = [\"aka_name\", \"license_\", \"location\"]\n",
    "    df = df.drop(columns_to_drop).unique()\n",
    "\n",
    "    columns_except_violations = [col for col in df.columns if col != \"violations\"]\n",
    "    for col in columns_except_violations:\n",
    "        df = df.filter(pl.col(col).is_not_null())\n",
    "\n",
    "    after_null_filter_rows = df.height\n",
    "    log(f\"After dropping nulls (except 'violations'): {after_null_filter_rows} rows\")\n",
    "\n",
    "    initial_violations_null = df.filter(pl.col(\"violations\").is_null()).height\n",
    "    drop_condition = (\n",
    "        (pl.col(\"violations\").is_null()) &\n",
    "        (~pl.col(\"results\").is_in([\"Pass\", \"Pass w/ Conditions\"]))\n",
    "    )\n",
    "    df = df.filter(~drop_condition)\n",
    "\n",
    "    remaining_violations_null = df.filter(pl.col(\"violations\").is_null()).height\n",
    "    removed_due_to_violations = initial_violations_null - remaining_violations_null\n",
    "\n",
    "    log(f\"Dropped {removed_due_to_violations} rows with missing violations and invalid results\")\n",
    "    log(f\"Preserved {remaining_violations_null} 'Pass' rows with no violations\")\n",
    "    log(f\"Final cleaned row count: {df.height}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a7a7e4-cd3f-4094-9029-4d32b54df844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Shape: (20000, 17)\n",
      "\n",
      "ðŸ“‹ Schema:\n",
      " - inspection_id: String\n",
      " - dba_name: String\n",
      " - aka_name: String\n",
      " - license_: String\n",
      " - facility_type: String\n",
      " - risk: String\n",
      " - address: String\n",
      " - city: String\n",
      " - state: String\n",
      " - zip: String\n",
      " - inspection_date: String\n",
      " - inspection_type: String\n",
      " - results: String\n",
      " - violations: String\n",
      " - latitude: String\n",
      " - longitude: String\n",
      " - location: Struct({'type': String, 'coordinates': List(Float64)})\n",
      "\n",
      "â“ Null counts per column:\n",
      " - inspection_id: 0\n",
      " - dba_name: 0\n",
      " - aka_name: 27\n",
      " - license_: 0\n",
      " - facility_type: 118\n",
      " - risk: 6\n",
      " - address: 0\n",
      " - city: 25\n",
      " - state: 5\n",
      " - zip: 0\n",
      " - inspection_date: 0\n",
      " - inspection_type: 0\n",
      " - results: 0\n",
      " - violations: 6443\n",
      " - latitude: 75\n",
      " - longitude: 75\n",
      " - location: 75\n",
      "ðŸ“ Shape: (16350, 14)\n",
      "\n",
      "ðŸ“‹ Schema:\n",
      " - inspection_id: String\n",
      " - dba_name: String\n",
      " - facility_type: String\n",
      " - risk: String\n",
      " - address: String\n",
      " - city: String\n",
      " - state: String\n",
      " - zip: String\n",
      " - inspection_date: String\n",
      " - inspection_type: String\n",
      " - results: String\n",
      " - violations: String\n",
      " - latitude: String\n",
      " - longitude: String\n",
      "\n",
      "â“ Null counts per column:\n",
      " - inspection_id: 0\n",
      " - dba_name: 0\n",
      " - facility_type: 0\n",
      " - risk: 0\n",
      " - address: 0\n",
      " - city: 0\n",
      " - state: 0\n",
      " - zip: 0\n",
      " - inspection_date: 0\n",
      " - inspection_type: 0\n",
      " - results: 0\n",
      " - violations: 3008\n",
      " - latitude: 0\n",
      " - longitude: 0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_1 = cleaner_1_drop(df, logger=logger)\n",
    "polars_info(df)\n",
    "polars_info(df_cleaned_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87019a83-e1f4-4de5-b02a-6b0b006bc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_2_inspection_id(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 2 cleaner: Validates and filters the inspection_id column.\n",
    "    - Drops rows with duplicate inspection_id\n",
    "    - Drops rows where inspection_id does not match 7-digit numeric string\n",
    "    - Logs action counts\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): DataFrame after cleaner_1\n",
    "        logger (optional): Logger object\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    before = df.height\n",
    "\n",
    "    # Step 1: Drop duplicates by inspection_id\n",
    "    df = df.unique(subset=[\"inspection_id\"])\n",
    "    after_dedup = df.height\n",
    "    dropped_duplicates = before - after_dedup\n",
    "    log(f\"Dropped {dropped_duplicates} duplicate inspection_id rows\")\n",
    "\n",
    "    # Step 2: Drop rows where inspection_id is not 7 digits\n",
    "    pattern = r\"^\\d{7}$\"\n",
    "    df = df.filter(pl.col(\"inspection_id\").str.contains(pattern))\n",
    "    after_pattern = df.height\n",
    "    dropped_bad_ids = after_dedup - after_pattern\n",
    "    log(f\"Dropped {dropped_bad_ids} rows with invalid inspection_id format\")\n",
    "\n",
    "    log(f\"Final row count after inspection_id checks: {df.height}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c26786-69fb-4909-8609-267a57cc0166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Shape: (16350, 14)\n",
      "\n",
      "ðŸ“‹ Schema:\n",
      " - inspection_id: String\n",
      " - dba_name: String\n",
      " - facility_type: String\n",
      " - risk: String\n",
      " - address: String\n",
      " - city: String\n",
      " - state: String\n",
      " - zip: String\n",
      " - inspection_date: String\n",
      " - inspection_type: String\n",
      " - results: String\n",
      " - violations: String\n",
      " - latitude: String\n",
      " - longitude: String\n",
      "\n",
      "â“ Null counts per column:\n",
      " - inspection_id: 0\n",
      " - dba_name: 0\n",
      " - facility_type: 0\n",
      " - risk: 0\n",
      " - address: 0\n",
      " - city: 0\n",
      " - state: 0\n",
      " - zip: 0\n",
      " - inspection_date: 0\n",
      " - inspection_type: 0\n",
      " - results: 0\n",
      " - violations: 3008\n",
      " - latitude: 0\n",
      " - longitude: 0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_2 = cleaner_2_inspection_id(df_cleaned_1, logger=logger)\n",
    "polars_info(df_cleaned_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0fe1824-d81d-43c4-8b73-07ac06ab3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_3_text_normalization(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 3 cleaner: Applies general text normalization to relevant columns.\n",
    "    - Lowercases, strips whitespace, removes punctuation, normalizes spaces\n",
    "    - Logs unique counts before and after for auditing\n",
    "    - Prints summary of changes to console\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): Input DataFrame\n",
    "        logger (optional): Logger object\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Normalized DataFrame\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    def normalize(col: pl.Expr) -> pl.Expr:\n",
    "        return (\n",
    "            col.str.strip_chars()\n",
    "               .str.to_lowercase()\n",
    "               .str.replace_all(r\"[^\\w\\s]\", \"\")  # remove punctuation\n",
    "               .str.replace_all(r\"\\s+\", \" \")     # normalize spaces\n",
    "        )\n",
    "\n",
    "    text_columns = [\n",
    "        \"dba_name\", \"facility_type\", \"risk\", \"address\",\n",
    "        \"city\", \"state\", \"inspection_type\", \"results\",\"violations\"\n",
    "    ]\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    for col in text_columns:\n",
    "        before = df.select(pl.col(col)).n_unique()\n",
    "        df = df.with_columns([normalize(pl.col(col)).alias(col)])\n",
    "        after = df.select(pl.col(col)).n_unique()\n",
    "        summary.append((col, before, after))\n",
    "        log(f\"{col}: unique values before = {before}, after = {after}\")\n",
    "\n",
    "    print(\"\\nColumn Normalization Summary:\")\n",
    "    for col, before, after in summary:\n",
    "        print(f\"{col:18} | Unique before: {before:<5} | Unique after: {after:<5}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44845f53-78df-4424-9cc1-d6bd35f1f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Normalization Summary:\n",
      "dba_name           | Unique before: 8966  | Unique after: 8831 \n",
      "facility_type      | Unique before: 123   | Unique after: 114  \n",
      "risk               | Unique before: 3     | Unique after: 3    \n",
      "address            | Unique before: 11156 | Unique after: 9086 \n",
      "city               | Unique before: 10    | Unique after: 6    \n",
      "state              | Unique before: 1     | Unique after: 1    \n",
      "inspection_type    | Unique before: 11    | Unique after: 11   \n",
      "results            | Unique before: 5     | Unique after: 5    \n",
      "violations         | Unique before: 13272 | Unique after: 13198\n",
      "ðŸ“ Shape: (16350, 14)\n",
      "\n",
      "ðŸ“‹ Schema:\n",
      " - inspection_id: String\n",
      " - dba_name: String\n",
      " - facility_type: String\n",
      " - risk: String\n",
      " - address: String\n",
      " - city: String\n",
      " - state: String\n",
      " - zip: String\n",
      " - inspection_date: String\n",
      " - inspection_type: String\n",
      " - results: String\n",
      " - violations: String\n",
      " - latitude: String\n",
      " - longitude: String\n",
      "\n",
      "â“ Null counts per column:\n",
      " - inspection_id: 0\n",
      " - dba_name: 0\n",
      " - facility_type: 0\n",
      " - risk: 0\n",
      " - address: 0\n",
      " - city: 0\n",
      " - state: 0\n",
      " - zip: 0\n",
      " - inspection_date: 0\n",
      " - inspection_type: 0\n",
      " - results: 0\n",
      " - violations: 3008\n",
      " - latitude: 0\n",
      " - longitude: 0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_3 =  cleaner_3_text_normalization(df_cleaned_2, logger=logger)\n",
    "polars_info(df_cleaned_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fed753e9-ac2c-445b-bea6-a9be7322c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def cleaner_4_values_consolidation(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 4 cleaner: Consolidates malformed values in city and risk.\n",
    "    - Uses fuzzy matching to correct common misspellings of \"chicago\"\n",
    "    - Normalizes risk values to \"high\", \"medium\", \"low\"\n",
    "    - Logs unique counts before and after cleaning\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): DataFrame to clean\n",
    "        logger (optional): Logger object\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    # Risk normalization map\n",
    "    risk_map = {\n",
    "        \"risk 1 high\": \"high\",\n",
    "        \"risk 2 medium\": \"medium\",\n",
    "        \"risk 3 low\": \"low\"\n",
    "    }\n",
    "\n",
    "    # Fuzzy correction function for city values\n",
    "    def fuzzy_fix_city(city: str) -> str:\n",
    "        if not city:\n",
    "            return city\n",
    "        if city == \"chicago\":\n",
    "            return city\n",
    "        if city in {\"chicagochicago\"}:\n",
    "            return \"chicago\"\n",
    "        if fuzz.ratio(city, \"chicago\") >= 70:\n",
    "            return \"chicago\"\n",
    "        return city\n",
    "\n",
    "    # Apply fuzzy city correction\n",
    "    before_unique_cities = df.select(\"city\").n_unique()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"city\").map_elements(fuzzy_fix_city, return_dtype=pl.String).alias(\"city\")\n",
    "    ])\n",
    "    after_unique_cities = df.select(\"city\").n_unique()\n",
    "    log(f\"City values: unique before = {before_unique_cities}, after = {after_unique_cities}\")\n",
    "\n",
    "    # Apply risk normalization using map_elements\n",
    "    before_unique_risks = df.select(\"risk\").n_unique()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"risk\").map_elements(lambda x: risk_map.get(x, x), return_dtype=pl.String).alias(\"risk\")\n",
    "    ])\n",
    "    after_unique_risks = df.select(\"risk\").n_unique()\n",
    "    log(f\"Risk values: unique before = {before_unique_risks}, after = {after_unique_risks}\")\n",
    "\n",
    "    log(f\"Final city values: {df.select('city').unique().to_series().to_list()}\")\n",
    "    log(f\"Final risk values: {df.select('risk').unique().to_series().to_list()}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cea94c11-518c-4e26-acca-d96318fa9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'city':\n",
      "['312chicago', 'chicagochicago', 'cchicago', 'chicago', 'berwyn', 'chicagoo']\n",
      "\n",
      "Unique values in 'state':\n",
      "['il']\n",
      "\n",
      "Unique values in 'risk':\n",
      "['risk 1 high', 'risk 3 low', 'risk 2 medium']\n",
      "\n",
      "Unique values in 'facility_type':\n",
      "['liquorgrocery', 'stadium', 'live poultry slaughter facility', 'wholesale', 'gas station store', 'live poultry slaughter', 'event space', 'shared kitchen', 'mobile frozen desserts vendor', 'commisary', 'unlicensed facility', 'daycare under 2 years', 'music venue', 'assisted living', 'banquets', 'vending commissary', 'grocery store', 'banquet hallcatering', 'thc infused bakery', 'entertainment venue', 'bakery', 'hotel', 'herbal life', 'rehab center', 'hospital', 'grocery storerestaurant', 'restaurantbar', 'grocery storegas station', 'regulated business', 'banquet', 'daycare above and under 2 years', 'event center', 'hot dog station', 'navy pier kiosk', 'senior day care', 'herbalife', 'donut shop', 'roof top', 'live poultry', 'daycare combo 1586', 'mobil food prepared', 'adult daycare', 'special event', 'grocerytaqueria', 'mobile food', 'assisted living senior care', 'long term care', 'church', 'churchspecial events', 'mobile food preparer', 'brewery', 'wholesale bakery', 'airport lounge', 'grocerysushi prep', 'mobile prepared food vendor', 'commissary', 'coffee kiosk', 'shelter', 'butcher deli', 'anotforprofit chef training program', 'dining hall', 'shared kitchen user long term', 'church food pantry', 'grocerybakery', 'cps charter', 'church kitchen', 'coffee shop', 'youth housing', 'daycare', 'banquet hall', 'gas station', 'rooftops', 'nursing home', 'cafeteria', 'teaching school', 'paleteria', 'cooking class', 'juice bar', 'daycare night', 'warehouse', 'restaurant', 'grocery storecooking school', 'tavern', 'shared kitchen user short term', 'cooking school', 'charter school', 'liquor', 'groceryrestaurant', 'mobile food dispenser', 'theater', 'food hall', 'supportive living', 'gym store', 'childrens services facility', 'rooftop', 'golden diner', 'school', 'restaurantgrocery store', 'private school', 'catering', 'public shcool', 'daycare 2 6 years', 'university cafeteria', 'store', 'roof tops', 'culinary school', 'grocery store plus wireless store', '1023 childerns services facility', 'ice cream shop', 'convenient store', 'free food pantry', 'charter', 'popup food establishment usertier ii', 'after school program']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'city':\")\n",
    "print(df_cleaned_3.select(\"city\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'state':\")\n",
    "print(df_cleaned_3.select(\"state\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'risk':\")\n",
    "print(df_cleaned_3.select(\"risk\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'facility_type':\")\n",
    "print(df_cleaned_3.select(\"facility_type\").unique().to_series().to_list())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1494132-7769-4e3e-af66-d3e513b4849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'city':\n",
      "['chicago', 'berwyn']\n",
      "\n",
      "Unique values in 'state':\n",
      "['il']\n",
      "\n",
      "Unique values in 'risk':\n",
      "['high', 'low', 'medium']\n",
      "\n",
      "Unique values in 'facility_type':\n",
      "['catering', 'gym store', 'coffee kiosk', 'gas station store', 'adult daycare', 'entertainment venue', 'banquets', 'church', 'wholesale', 'coffee shop', 'dining hall', 'mobile food dispenser', 'daycare above and under 2 years', 'commisary', 'live poultry slaughter', 'after school program', 'shared kitchen user short term', 'navy pier kiosk', 'university cafeteria', 'private school', 'grocery storerestaurant', 'grocerybakery', 'special event', 'daycare night', 'hospital', 'shared kitchen', 'charter', 'daycare', 'live poultry', 'banquet hall', 'food hall', 'music venue', 'youth housing', 'commissary', 'juice bar', 'event center', 'mobile frozen desserts vendor', 'gas station', 'grocery store', 'grocery storegas station', 'roof tops', 'banquet', 'theater', 'assisted living', 'grocerytaqueria', 'supportive living', 'liquorgrocery', 'daycare under 2 years', 'shelter', 'live poultry slaughter facility', 'mobile prepared food vendor', 'hotel', 'butcher deli', 'popup food establishment usertier ii', 'bakery', 'event space', 'airport lounge', 'shared kitchen user long term', 'rehab center', 'liquor', 'roof top', 'cafeteria', 'groceryrestaurant', 'church food pantry', 'grocery store plus wireless store', 'churchspecial events', 'long term care', 'ice cream shop', 'church kitchen', 'banquet hallcatering', 'wholesale bakery', 'brewery', 'herbal life', 'warehouse', 'assisted living senior care', 'tavern', 'daycare 2 6 years', 'charter school', 'free food pantry', 'rooftops', 'restaurantbar', 'grocery storecooking school', 'thc infused bakery', 'hot dog station', 'store', 'school', 'restaurantgrocery store', 'convenient store', '1023 childerns services facility', 'vending commissary', 'cooking class', 'anotforprofit chef training program', 'herbalife', 'mobile food', 'regulated business', 'grocerysushi prep', 'culinary school', 'golden diner', 'cooking school', 'nursing home', 'stadium', 'daycare combo 1586', 'mobil food prepared', 'senior day care', 'public shcool', 'donut shop', 'rooftop', 'paleteria', 'mobile food preparer', 'cps charter', 'childrens services facility', 'teaching school', 'unlicensed facility', 'restaurant']\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_4 =  cleaner_4_values_consolidation(df_cleaned_3, logger=logger)\n",
    "#polars_info(df_cleaned_4)\n",
    "\n",
    "print(\"Unique values in 'city':\")\n",
    "print(df_cleaned_4.select(\"city\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'state':\")\n",
    "print(df_cleaned_4.select(\"state\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'risk':\")\n",
    "print(df_cleaned_4.select(\"risk\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'facility_type':\")\n",
    "print(df_cleaned_4.select(\"facility_type\").unique().to_series().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fee2f067-52eb-48c8-8207-3ba0035005e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_5_facility_type(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Step 5 cleaner: Consolidates noisy facility_type strings into a controlled category set.\n",
    "    - Uses a tag-based match system to assign standard categories\n",
    "    - Falls back to 'unknown' when no tags match\n",
    "    - Logs frequency of categories for validation\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): Input DataFrame\n",
    "        logger (optional): Logger object\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with a new column 'facility_category'\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    category_tags = {\n",
    "        \"hospital\":[\"hospital\",\"clinic\"],\n",
    "        \"condiments\": [\"juice bar\", \"ice cream\", \"dessert\", \"donut\", \"snack\",\"gym\",\"herbal\"],\n",
    "        \"school\": [\"school\", \"charter\", \"public shcool\", \"teaching\"],\n",
    "        \"butcher\": [\"butcher\", \"meat\",\"slaughter\",\"live\"],\n",
    "        \"supportive_living\": [\"assisted living\", \"supportive\", \"senior\", \"rehab\", \"adult daycare\", \"nursing home\", \"long term care\"],\n",
    "        \"event\": [\"event\", \"venue\", \"hall\", \"roof\", \"banquet\",\"banquets\",\"theater\",\"catering\",\"stadium\"],\n",
    "        \"gas_station\": [\"gas station\", \"station store\", \"station\", \"convenient store\"],\n",
    "        \"restaurant\": [\"restaurant\", \"banquet\", \"diner\", \"taqueria\", \"bar\", \"pub\"],\n",
    "        \"mobile\": [\"mobile\", \"mobil\", \"dispenser\", \"truck\", \"prepared\",\"hot dog\",\"popup\"],\n",
    "        \"gas_station\": [\"gas station\", \"station store\", \"convenient store\"],\n",
    "        \"grocery\": [\"grocery\", \"market\", \"store\", \"food mart\"],\n",
    "        \"coffee\": [\"coffee\", \"tea\", \"cafe\", \"espresso\", \"kiosk\"],\n",
    "        \"bakery\": [\"bakery\", \"paleteria\", \"donut\", \"dessert\"],\n",
    "        \"bar\": [\"tavern\", \"liquor\", \"bar\",\"lounge\",\"brewery\"],      \n",
    "        \"cooking_school\": [\"cooking\", \"culinary\", \"training\", \"chef\"],\n",
    "        \"child_services\": [\"daycare\", \"after school\", \"child\", \"children\",\"youth\"],\n",
    "        \"church\": [\"church\", \"faith\", \"religious\"],\n",
    "        \"commissary\": [\"commissary\", \"commisary\",\"shared kitchen\",\"shelter\"],\n",
    "        \"pantry\": [\"pantry\", \"free food\"],        \n",
    "        \"hotel\": [\"hotel\", \"lodge\", \"inn\"],\n",
    "        \"warehouse\": [\"warehouse\", \"distribution\",\"wholesale\"],      \n",
    "        \"facility\": [\"facility\", \"services\",\"regulated\"],\n",
    "        \"restaurant\": [\"restaurant\",  \"diner\", \"taqueria\", \"cafeteria\"], \n",
    "        \"unknown\": []\n",
    "    }\n",
    "\n",
    "    def categorize(text: str) -> str:\n",
    "        if not text:\n",
    "            return \"unknown\"\n",
    "        text = text.lower().strip()\n",
    "        for category, tags in category_tags.items():\n",
    "            for tag in tags:\n",
    "                if tag in text:\n",
    "                    return category\n",
    "        return \"unknown\"\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"facility_type\").map_elements(categorize, return_dtype=pl.String).alias(\"facility_category\")\n",
    "    ])\n",
    "\n",
    "    # Count category frequencies for inspection\n",
    "    counts = (\n",
    "        df.group_by(\"facility_category\")\n",
    "          .count()\n",
    "          .sort(\"facility_category\")\n",
    "    )\n",
    "\n",
    "    log(\"Facility category counts:\")\n",
    "    for row in counts.rows():\n",
    "        log(f\"  {row[0]}: {row[1]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "208a0f25-daec-4922-8b2f-696d8120ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Mapping of raw facility types to consolidated categories:\n",
      "bakery                                             â†’ bakery\n",
      "paleteria                                          â†’ bakery\n",
      "thc infused bakery                                 â†’ bakery\n",
      "wholesale bakery                                   â†’ bakery\n",
      "airport lounge                                     â†’ bar\n",
      "brewery                                            â†’ bar\n",
      "liquor                                             â†’ bar\n",
      "tavern                                             â†’ bar\n",
      "butcher deli                                       â†’ butcher\n",
      "live poultry                                       â†’ butcher\n",
      "live poultry slaughter                             â†’ butcher\n",
      "live poultry slaughter facility                    â†’ butcher\n",
      "1023 childerns services facility                   â†’ child_services\n",
      "childrens services facility                        â†’ child_services\n",
      "daycare                                            â†’ child_services\n",
      "daycare 2 6 years                                  â†’ child_services\n",
      "daycare above and under 2 years                    â†’ child_services\n",
      "daycare combo 1586                                 â†’ child_services\n",
      "daycare night                                      â†’ child_services\n",
      "daycare under 2 years                              â†’ child_services\n",
      "youth housing                                      â†’ child_services\n",
      "church                                             â†’ church\n",
      "church food pantry                                 â†’ church\n",
      "church kitchen                                     â†’ church\n",
      "coffee kiosk                                       â†’ coffee\n",
      "coffee shop                                        â†’ coffee\n",
      "navy pier kiosk                                    â†’ coffee\n",
      "commisary                                          â†’ commissary\n",
      "commissary                                         â†’ commissary\n",
      "shared kitchen                                     â†’ commissary\n",
      "shared kitchen user long term                      â†’ commissary\n",
      "shared kitchen user short term                     â†’ commissary\n",
      "shelter                                            â†’ commissary\n",
      "vending commissary                                 â†’ commissary\n",
      "donut shop                                         â†’ condiments\n",
      "gym store                                          â†’ condiments\n",
      "herbal life                                        â†’ condiments\n",
      "herbalife                                          â†’ condiments\n",
      "ice cream shop                                     â†’ condiments\n",
      "juice bar                                          â†’ condiments\n",
      "mobile frozen desserts vendor                      â†’ condiments\n",
      "anotforprofit chef training program                â†’ cooking_school\n",
      "cooking class                                      â†’ cooking_school\n",
      "banquet                                            â†’ event\n",
      "banquet hall                                       â†’ event\n",
      "banquet hallcatering                               â†’ event\n",
      "banquets                                           â†’ event\n",
      "catering                                           â†’ event\n",
      "churchspecial events                               â†’ event\n",
      "dining hall                                        â†’ event\n",
      "entertainment venue                                â†’ event\n",
      "event center                                       â†’ event\n",
      "event space                                        â†’ event\n",
      "food hall                                          â†’ event\n",
      "music venue                                        â†’ event\n",
      "roof top                                           â†’ event\n",
      "roof tops                                          â†’ event\n",
      "rooftop                                            â†’ event\n",
      "rooftops                                           â†’ event\n",
      "special event                                      â†’ event\n",
      "stadium                                            â†’ event\n",
      "theater                                            â†’ event\n",
      "regulated business                                 â†’ facility\n",
      "unlicensed facility                                â†’ facility\n",
      "convenient store                                   â†’ gas_station\n",
      "gas station                                        â†’ gas_station\n",
      "gas station store                                  â†’ gas_station\n",
      "grocery storegas station                           â†’ gas_station\n",
      "grocery store                                      â†’ grocery\n",
      "grocery store plus wireless store                  â†’ grocery\n",
      "grocerybakery                                      â†’ grocery\n",
      "grocerysushi prep                                  â†’ grocery\n",
      "liquorgrocery                                      â†’ grocery\n",
      "store                                              â†’ grocery\n",
      "hospital                                           â†’ hospital\n",
      "hotel                                              â†’ hotel\n",
      "hot dog station                                    â†’ mobile\n",
      "mobil food prepared                                â†’ mobile\n",
      "mobile food                                        â†’ mobile\n",
      "mobile food dispenser                              â†’ mobile\n",
      "mobile food preparer                               â†’ mobile\n",
      "mobile prepared food vendor                        â†’ mobile\n",
      "popup food establishment usertier ii               â†’ mobile\n",
      "free food pantry                                   â†’ pantry\n",
      "cafeteria                                          â†’ restaurant\n",
      "golden diner                                       â†’ restaurant\n",
      "grocery storerestaurant                            â†’ restaurant\n",
      "groceryrestaurant                                  â†’ restaurant\n",
      "grocerytaqueria                                    â†’ restaurant\n",
      "restaurant                                         â†’ restaurant\n",
      "restaurantbar                                      â†’ restaurant\n",
      "restaurantgrocery store                            â†’ restaurant\n",
      "university cafeteria                               â†’ restaurant\n",
      "after school program                               â†’ school\n",
      "charter                                            â†’ school\n",
      "charter school                                     â†’ school\n",
      "cooking school                                     â†’ school\n",
      "cps charter                                        â†’ school\n",
      "culinary school                                    â†’ school\n",
      "grocery storecooking school                        â†’ school\n",
      "private school                                     â†’ school\n",
      "public shcool                                      â†’ school\n",
      "school                                             â†’ school\n",
      "teaching school                                    â†’ school\n",
      "adult daycare                                      â†’ supportive_living\n",
      "assisted living                                    â†’ supportive_living\n",
      "assisted living senior care                        â†’ supportive_living\n",
      "long term care                                     â†’ supportive_living\n",
      "nursing home                                       â†’ supportive_living\n",
      "rehab center                                       â†’ supportive_living\n",
      "senior day care                                    â†’ supportive_living\n",
      "supportive living                                  â†’ supportive_living\n",
      "warehouse                                          â†’ warehouse\n",
      "wholesale                                          â†’ warehouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malaw\\AppData\\Local\\Temp\\ipykernel_39184\\2609797114.py:74: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  .count()\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_5 =  cleaner_5_facility_type(df_cleaned_4, logger=logger)\n",
    "\n",
    "mapping_summary = (\n",
    "    df_cleaned_5\n",
    "    .select([\"facility_type\", \"facility_category\"])\n",
    "    .unique()\n",
    "    .sort(by=[\"facility_category\", \"facility_type\"])\n",
    ")\n",
    "\n",
    "print(\"ðŸ“‹ Mapping of raw facility types to consolidated categories:\")\n",
    "for row in mapping_summary.rows():\n",
    "    print(f\"{row[0]:50} â†’ {row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42fedd9b-b5a9-4a7e-97da-34b26674fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'inspection_type':\n",
      "['suspected food poisoning', 'consultation', 'license reinspection', 'canvass', 'complaint', 'complaint reinspection', 'short form complaint', 'license', 'noninspection', 'canvass reinspection', 'recent inspection']\n",
      "\n",
      "Unique values in 'results':\n",
      "['pass w conditions', 'not ready', 'pass', 'no entry', 'fail']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique values in 'inspection_type':\")\n",
    "print(df_cleaned_5.select(\"inspection_type\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'results':\")\n",
    "print(df_cleaned_5.select(\"results\").unique().to_series().to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49cb5c1b-7cb1-44c2-9596-01f5169f1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_6_inspection_type(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes and categorizes inspection_type values.\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    def normalize_type(val: str) -> str:\n",
    "        val = val.lower().strip()\n",
    "        if \"canvass\" in val: return \"routine\"\n",
    "        if \"license\" in val: return \"license\"\n",
    "        if \"complaint\" in val: return \"complaint\"\n",
    "        if \"consultation\" in val: return \"consultation\"\n",
    "        if \"food poisoning\" in val: return \"food_poisoning\"\n",
    "        if \"short form\" in val: return \"complaint\"\n",
    "        if \"recent\" in val: return \"recent\"\n",
    "        if \"noninspection\" in val: return \"noninspection\"\n",
    "        return val.replace(\" \", \"_\")  # fallback normalization\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"inspection_type\").map_elements(normalize_type, return_dtype=pl.String).alias(\"inspection_type\")\n",
    "    ])\n",
    "\n",
    "    log(\"Unique inspection_type values after standardization:\")\n",
    "    for val in df.select(\"inspection_type\").unique().to_series().to_list():\n",
    "        log(f\"  {val}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def cleaner_7_results(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes results field (spacing, casing, underscores).\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    def normalize_result(val: str) -> str:\n",
    "        val = val.lower().strip().replace(\" \", \"_\")\n",
    "        return val\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"results\").map_elements(normalize_result, return_dtype=pl.String).alias(\"results\")\n",
    "    ])\n",
    "\n",
    "    log(\"Unique results values after standardization:\")\n",
    "    for val in df.select(\"results\").unique().to_series().to_list():\n",
    "        log(f\"  {val}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "964b67b0-45e6-45b6-ab50-da1cfdd53d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'inspection_type':\n",
      "['license', 'consultation', 'recent', 'noninspection', 'food_poisoning', 'routine', 'complaint']\n",
      "\n",
      "Unique values in 'results':\n",
      "['fail', 'pass_w_conditions', 'no_entry', 'not_ready', 'pass']\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_6 =  cleaner_6_inspection_type(df_cleaned_5, logger=logger)\n",
    "df_cleaned_7 =  cleaner_7_results(df_cleaned_6, logger=logger)\n",
    "\n",
    "print(\"\\nUnique values in 'inspection_type':\")\n",
    "print(df_cleaned_6.select(\"inspection_type\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nUnique values in 'results':\")\n",
    "print(df_cleaned_7.select(\"results\").unique().to_series().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31d94a3c-7128-42d3-818d-71220ce9c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_8_geolocation(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates ZIP, latitude, and longitude fields.\n",
    "    - Drops rows with invalid or missing ZIP (non-5-digit)\n",
    "    - Drops rows with non-numeric or out-of-bounds lat/lon\n",
    "    - Converts lat/lon to float for modeling/visualization\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): Input DataFrame\n",
    "        logger (optional): Logger for output\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Cleaned DataFrame with valid geolocation info\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if logger:\n",
    "            try:\n",
    "                logger.info(msg.encode(\"ascii\", \"ignore\").decode())\n",
    "            except Exception:\n",
    "                logger.info(\"LOG ERROR (unicode removed): \" + msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "\n",
    "    original_rows = df.height\n",
    "\n",
    "    # Normalize zip\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"zip\").str.strip_chars().str.zfill(5).alias(\"zip\")\n",
    "    ])\n",
    "\n",
    "    # Ensure ZIP is string, stripped, and padded\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"zip\").cast(pl.Utf8, strict=False)\n",
    "            .str.strip_chars()\n",
    "            .str.replace_all(r\"[^\\d]\", \"\")\n",
    "            .str.zfill(5)\n",
    "            .alias(\"zip\")\n",
    "    ])\n",
    "\n",
    "    # Drop rows where ZIP is not a valid 5-digit string\n",
    "    df = df.filter(\n",
    "        pl.col(\"zip\").is_not_null() &\n",
    "           (pl.col(\"zip\").str.len_chars() == 5)\n",
    "\n",
    "    )\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"zip\").cast(pl.Utf8, strict=False)\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # Coerce lat/lon to float\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"latitude\").cast(pl.Float64, strict=False),\n",
    "        pl.col(\"longitude\").cast(pl.Float64, strict=False)\n",
    "    ])\n",
    "\n",
    "    # Drop rows with missing or invalid lat/lon\n",
    "    df = df.filter(\n",
    "        (pl.col(\"latitude\").is_not_null()) &\n",
    "        (pl.col(\"longitude\").is_not_null()) &\n",
    "        (pl.col(\"latitude\") >= -90) & (pl.col(\"latitude\") <= 90) &\n",
    "        (pl.col(\"longitude\") >= -180) & (pl.col(\"longitude\") <= 180)\n",
    "    )\n",
    "\n",
    "    # Round latitude and longitude to 5 decimal places\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"latitude\").round(5),\n",
    "        pl.col(\"longitude\").round(5)\n",
    "    ])\n",
    "    \n",
    "    log(f\"Geolocation cleaner: {original_rows - df.height} rows dropped (invalid zip/lat/lon)\")\n",
    "    log(f\"Remaining rows: {df.height}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e816c684-2504-47de-985d-8a827e6c04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'zip':\n",
      "['60649', '60647', '60603', '60604', '60629', '60623', '60659', '60644', '60653', '60614', '60654', '60611', '60630', '60613', '60621', '60624', '60634', '60633', '60660', '60607', '60651', '60707', '60657', '60655', '60628', '60645', '60637', '60666', '60606', '60638', '60622', '60643', '60661', '60609', '60605', '60402', '60608', '60656', '60640', '60617', '60625', '60610', '60641', '60612', '60646', '60652', '60626', '60632', '60615', '60616', '60639', '60642', '60636', '60631', '60602', '60620', '60618', '60601', '60827', '60619']\n",
      "\n",
      "Sample (latitude, longitude) pairs:\n",
      "(41.97974, -87.66774)\n",
      "(41.73893, -87.60503)\n",
      "(41.95967, -87.68246)\n",
      "(41.99946, -87.76182)\n",
      "(41.88478, -87.6308)\n",
      "(41.96531, -87.65578)\n",
      "(41.9763, -87.66828)\n",
      "(41.96855, -87.68548)\n",
      "(41.90715, -87.66417)\n",
      "(41.87281, -87.67745)\n",
      "(41.89267, -87.62257)\n",
      "(42.0183, -87.66686)\n",
      "(41.97592, -87.70056)\n",
      "(41.93322, -87.65942)\n",
      "(41.90091, -87.62403)\n",
      "(41.89428, -87.63726)\n",
      "(41.85807, -87.6558)\n",
      "(41.87791, -87.64141)\n",
      "(41.98573, -87.83271)\n",
      "(41.96877, -87.67002)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_8 =  cleaner_8_geolocation(df_cleaned_7, logger=logger)\n",
    "\n",
    "print(\"\\nUnique values in 'zip':\")\n",
    "print(df_cleaned_8.select(\"zip\").unique().to_series().to_list())\n",
    "\n",
    "print(\"\\nSample (latitude, longitude) pairs:\")\n",
    "\n",
    "# Collect and display as list of tuples\n",
    "lat_lon_pairs = (\n",
    "    df_cleaned_8\n",
    "    .select([\"latitude\", \"longitude\"])\n",
    "    .unique()\n",
    "    .rows()\n",
    ")\n",
    "\n",
    "# Print as list of pairs\n",
    "for pair in lat_lon_pairs[:20]:  # limit to first 20 for readability\n",
    "    print(pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a409d889-b96b-40c2-9e11-fdbf065998f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cleaner_9_tokenize_violations(df: pl.DataFrame, logger=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Tokenizes and indexes violations.\n",
    "    - Extracts violation codes from raw text\n",
    "    - Adds `violation_codes`, `violation_count`, and `hand_hygiene_flag`\n",
    "\n",
    "    Parameters:\n",
    "        df (pl.DataFrame): Cleaned data with 'violations' column\n",
    "        logger (optional): Logger for audit output\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Updated with new violation features\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        try:\n",
    "            text = str(msg)  # convert anything to string first\n",
    "            if logger:\n",
    "                try:\n",
    "                    logger.info(text.encode(\"ascii\", \"ignore\").decode())\n",
    "                except Exception:\n",
    "                    logger.info(\"LOG ERROR (unicode removed): \" + text)\n",
    "            else:\n",
    "                print(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Logging error: {e}\")\n",
    "\n",
    "\n",
    "    HAND_HYGIENE_CODES = {5, 6, 7, 8, 33, 34, 36, 60, 61}  # codes related to sinks, soap, handwashing, etc.\n",
    "\n",
    "    def extract_violation_codes(text: str) -> list[int]:\n",
    "        if not text:\n",
    "            return []\n",
    "        matches = re.findall(r\"(?:^|\\s)(\\d{1,2})(?=\\s)\", text)\n",
    "        return [int(code) for code in matches]\n",
    "\n",
    "\n",
    "    def contains_hand_hygiene(codes: list[int]) -> int:\n",
    "        return int(any(code in HAND_HYGIENE_CODES for code in codes))\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"violations\").fill_null(\"\").map_elements(extract_violation_codes, return_dtype=pl.List(pl.Int64)).alias(\"violation_codes\")\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"violation_codes\").list.len().alias(\"violation_count\"),\n",
    "        pl.col(\"violation_codes\").map_elements(contains_hand_hygiene, return_dtype=pl.Int8).alias(\"hand_hygiene_flag\")\n",
    "    ])\n",
    "\n",
    "    log(\"âœ… Violation parsing complete.\")\n",
    "    log(\"Sample output:\")\n",
    "    for row in df.select([\"violation_codes\", \"violation_count\", \"hand_hygiene_flag\"]).limit(5).rows():\n",
    "        log(row)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18e7107d-003c-4681-9b53-49b63be12f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Sample full violation texts:\n",
      "- 10 adequate handwashing sinks properly supplied and accessible comments observed missing handwashing signs at handsinks in basement and kitchen prep area instructed to install and maintain 51 plumbing installed proper backflow devices comments observed missing backflow device at utility sink in basement mop sink area instructed to install and maintain 51 plumbing installed proper backflow devices comments observed loose faucet at handsink in employee restroom instructed to repair and maintan 56 adequate ventilation lighting designated areas used comments observed an accumulation of dirtdebris buildup on the toilet room exhaust ventilation must detail clean and maintain\n",
      "- 56 adequate ventilation lighting designated areas used comments observed ventilation hood not operable in basement prep area instructed manager to repair and maintain\n",
      "- 51 plumbing installed proper backflow devices comments observed a leak at the three compartment sink faucet instructed to repair and maintain\n",
      "- 10 adequate handwashing sinks properly supplied and accessible comments 630114 observed no handwashing signage at the handwashing sink behind the bar area instructed to provide and maintain 38 insects rodents animals not present comments 6501112 observed dead bugs in the basins of the three compartment sink instructed to remove dead bugs clean and sanitize basins before service and maintain 38 insects rodents animals not present comments 620215 observed an opening at the bottom of the rear exit door in the rear food prepdishwashing area instructed to rodent proof mentioned door and maintain 39 contamination prevented during food preparation storage display comments 330711 observed the deep fryer unit uncovered with grease while not in service instructed to cover to prevent contamination and maintain 49 nonfoodfood contact surfaces clean comments 460111c observed slight debris in the lower compartment of the deepfrying unit instructed to clean and maintain\n",
      "- 1 person in charge present demonstrates knowledge and performs duties comments 210111 observed the person in charge at the beginning of the inspection without a city of chicago food service sanitation managers certificate instructed all persons in charge must obtain a city of chicago food service sanitation managers certificate priority foundation citation issued under violation 2 2 city of chicago food service sanitation certificate comments 210111 observed no city of chicago food service sanitation manager on site while tcs foods shrimp chicken are being prepared handled and served to the public instructed a city of chicago food service sanitation manager must be on site at all times the facility is open and operating priority foundation citation issued 738012 10 adequate handwashing sinks properly supplied and accessible comments 630114 observed the rear dish room hand washing sink without a hand washing sign instructed to provide 35 approved thawing methods used comments 350113 observed the facility improperly thawing raw pork at room temperature temperature of the product did not exceed 41f instructed to always properly thaw all tcs foods under cold running water not exceeding a coldwater temperature of 70f or in a refrigeration unit 57 all food employees have food handler training comments 210213 observed one female and one male food handler without proof of food handler training instructed to meet requirement within 30 days of hire\n",
      "- 51 plumbing installed proper backflow devices comments leak ar ptrap on 3 compartment sink instructed to correct and maintain\n",
      "- 12 food received at proper temperature comments noted prepared hot tcs vegetable tortilla soup delivered and accepted at improper hot holding temperature from the catering co soup noted at 125f instructed to reheat soup to 165f on the kitchens electric hot plate reviewed temperature requirements priority violation 738005 citation issued 16 foodcontact surfaces cleaned sanitized comments some interior areas of the ice machine in need of cleaning 37 food properly labeled original container comments all bulk foods not stored in their original containers must be labeled with the product common name 43 inuse utensils properly stored comments ice scoops noted improperly stored on top of the ice machine must store in a clean container 45 singleusesingleservice articles properly stored used comments clean aluminum service pans must be stored invertedall stored items throughout the rear chemical storage room must be elevated from the floors 49 nonfoodfood contact surfaces clean comments noted peeling plastic on metal surfaces of the dish washing machine instructed to remove all 55 physical facilities installed maintained clean comments observed no smooth cleanable ceiling above the food prep tables refrigeration units above the dish area and ice machine noted papertape wrapped waste water piping that is peeling torn with exposed insulation instructed to provide a smooth cleanable ceiling throughout the kitchen\n",
      "- 9 no bare hand contact with rte food or a preapproved alternative procedure properly allowed comments observed cook on the cooks line handle ready to eat foods such as breakfast sandwich bun toppings for sandwich ie bacon and cheese with bare hands reviewed good hygienic practices of no bare hand contact with ready to eat foods manager requested employee to wash hands and wear gloves priority violation 738010 citation issued 16 foodcontact surfaces cleaned sanitized comments interior of the ice machine in need of cleaning must clean all interior surfaces and maintain 21 proper hot holding temperatures comments observed approximately 5 lbs cooked potatoes in a container being stored on an unused fryer at an improper temperature of 93f no temperature logs maintained on site reviewed proper hot and cold holding temperature all discarded priority violation 738005 citation issued 37 food properly labeled original container comments all bulk foods not stored in the original container including spices must be labeled with the product common name 41 wiping cloths properly used stored comments all prep area wiping cloths must be held in a clean container with a sanitizing solution 47 food nonfood contact surfaces cleanable properly designed constructed used comments must not use milk crates as a means of elevation for stored items throughoutraw wooden 2x4s used as elevation under the three compartment sink grease trap must be paintedsealed and non absorbent 55 physical facilities installed maintained clean comments noted peeling plastic used as a protectant on the wall behind and under the three compartment sink must be removednoted dirty floor drain under the three compartment sink must clean and maintainmissing ceiling tile above the walkin cooler must replace 55 physical facilities installed maintained clean comments noted damaged baseboard coving peeling from the wall in the hallway storage area leading to the washroom must replacerepair\n",
      "- 47 food nonfood contact surfaces cleanable properly designed constructed used comments ice build up in the milk cooler in the dining area instructed to remove and maintain 47 food nonfood contact surfaces cleanable properly designed constructed used comments the middle washbowls in the boysgirls toilet rooms in the rear stairwell needs to be recaulked at the top instructed to recaulk and maintain 51 plumbing installed proper backflow devices comments the middle knob on the faucet of the 3compartment sink in the food prep area leaks instructed to fix the leak and maintain good plumbing 55 physical facilities installed maintained clean comments the boys toilet room in the rear stairwell has water stained ceiling tiles instructed to replace and maintain 55 physical facilities installed maintained clean comments mop not properly stored to air dry when not in use instructed to store hanging up to properly air dry maintain 56 adequate ventilation lighting designated areas used comments light shield in the boys toilet room located in the rear stairwell is missing instructed to provide and maintain\n",
      "- 10 adequate handwashing sinks properly supplied and accessible comments 630114 observed handsinks without handwashing signage instructed to provide 51 plumbing installed proper backflow devices comments 520313 observed mop sink inoperable during time of inspection intructed to repair 55 physical facilities installed maintained clean comments 620113 observed broken missing tile base throughout rear unused prep areastorage area throughout instructed to provide and maintain to prevent pest breeding sites 55 physical facilities installed maintained clean comments 620111 observed flooring in front behind 3 door cooling units near front door in rear grocery area underneath display coolers noted drywall in disrepair along north wall of store where cooling units are stored excessive peeling paint and holes in wall in rear storage area throughout above shelving racks instructed to provide smooth and easily cleanable walls and flooring throughout premise must maintain 55 physical facilities installed maintained clean comments 6501114 observed excessive amounts of trash unused equipment and miscellaneus items stored in back yard area throughout instructed to remove all said items to prevent hiding spaces for pest must maintain premise 55 physical facilities installed maintained clean comments 620117 observed missing ceiling tiles throughout grocery and rear prep instructed to replace\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show full text for a few sample violations\n",
    "sample_violations = (\n",
    "    df_cleaned_8\n",
    "    .select(\"violations\")\n",
    "    .filter(pl.col(\"violations\").is_not_null() & (pl.col(\"violations\").str.len_chars() > 10))\n",
    "    .limit(10)\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ” Sample full violation texts:\")\n",
    "for v in sample_violations:\n",
    "    print(\"-\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ef0473ef-f28c-4ba9-b618-c972cb140c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "Schema([('inspection_id', String), ('dba_name', String), ('facility_type', String), ('risk', String), ('address', String), ('city', String), ('state', String), ('zip', String), ('inspection_date', String), ('inspection_type', String), ('results', String), ('violations', String), ('latitude', Float64), ('longitude', Float64), ('facility_category', String), ('violation_codes', List(Int64)), ('violation_count', UInt32), ('hand_hygiene_flag', Int8)])\n",
      "\n",
      "Sample violations preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>inspection_id</th><th>results</th><th>violation_codes</th><th>violation_count</th><th>hand_hygiene_flag</th></tr><tr><td>str</td><td>str</td><td>list[i64]</td><td>u32</td><td>i8</td></tr></thead><tbody><tr><td>&quot;2602529&quot;</td><td>&quot;pass&quot;</td><td>[10, 51, â€¦ 56]</td><td>4</td><td>0</td></tr><tr><td>&quot;2608217&quot;</td><td>&quot;pass&quot;</td><td>[56]</td><td>1</td><td>0</td></tr><tr><td>&quot;2603058&quot;</td><td>&quot;pass&quot;</td><td>[51]</td><td>1</td><td>0</td></tr><tr><td>&quot;2595709&quot;</td><td>&quot;pass&quot;</td><td>[10, 38, â€¦ 49]</td><td>5</td><td>0</td></tr><tr><td>&quot;2608554&quot;</td><td>&quot;pass_w_conditions&quot;</td><td>[1, 2, â€¦ 30]</td><td>7</td><td>0</td></tr><tr><td>&quot;2604669&quot;</td><td>&quot;pass&quot;</td><td>[51, 3]</td><td>2</td><td>0</td></tr><tr><td>&quot;2608796&quot;</td><td>&quot;pass_w_conditions&quot;</td><td>[12, 16, â€¦ 55]</td><td>7</td><td>0</td></tr><tr><td>&quot;2600286&quot;</td><td>&quot;pass_w_conditions&quot;</td><td>[9, 16, â€¦ 55]</td><td>9</td><td>1</td></tr><tr><td>&quot;2603269&quot;</td><td>&quot;pass&quot;</td><td>[47, 47, â€¦ 56]</td><td>6</td><td>0</td></tr><tr><td>&quot;2612844&quot;</td><td>&quot;pass&quot;</td><td>[10, 51, â€¦ 55]</td><td>7</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ inspection_id â”† results           â”† violation_codes â”† violation_count â”† hand_hygiene_flag â”‚\n",
       "â”‚ ---           â”† ---               â”† ---             â”† ---             â”† ---               â”‚\n",
       "â”‚ str           â”† str               â”† list[i64]       â”† u32             â”† i8                â”‚\n",
       "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 2602529       â”† pass              â”† [10, 51, â€¦ 56]  â”† 4               â”† 0                 â”‚\n",
       "â”‚ 2608217       â”† pass              â”† [56]            â”† 1               â”† 0                 â”‚\n",
       "â”‚ 2603058       â”† pass              â”† [51]            â”† 1               â”† 0                 â”‚\n",
       "â”‚ 2595709       â”† pass              â”† [10, 38, â€¦ 49]  â”† 5               â”† 0                 â”‚\n",
       "â”‚ 2608554       â”† pass_w_conditions â”† [1, 2, â€¦ 30]    â”† 7               â”† 0                 â”‚\n",
       "â”‚ 2604669       â”† pass              â”† [51, 3]         â”† 2               â”† 0                 â”‚\n",
       "â”‚ 2608796       â”† pass_w_conditions â”† [12, 16, â€¦ 55]  â”† 7               â”† 0                 â”‚\n",
       "â”‚ 2600286       â”† pass_w_conditions â”† [9, 16, â€¦ 55]   â”† 9               â”† 1                 â”‚\n",
       "â”‚ 2603269       â”† pass              â”† [47, 47, â€¦ 56]  â”† 6               â”† 0                 â”‚\n",
       "â”‚ 2612844       â”† pass              â”† [10, 51, â€¦ 55]  â”† 7               â”† 0                 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total inspections with hand hygiene-related violations: 3933\n",
      "\n",
      "Hand hygiene violations by inspection result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>results</th><th>hand_hygiene_count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;fail&quot;</td><td>1857</td></tr><tr><td>&quot;pass_w_conditions&quot;</td><td>1110</td></tr><tr><td>&quot;pass&quot;</td><td>940</td></tr><tr><td>&quot;no_entry&quot;</td><td>26</td></tr><tr><td>&quot;not_ready&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ results           â”† hand_hygiene_count â”‚\n",
       "â”‚ ---               â”† ---                â”‚\n",
       "â”‚ str               â”† i64                â”‚\n",
       "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ fail              â”† 1857               â”‚\n",
       "â”‚ pass_w_conditions â”† 1110               â”‚\n",
       "â”‚ pass              â”† 940                â”‚\n",
       "â”‚ no_entry          â”† 26                 â”‚\n",
       "â”‚ not_ready         â”† 0                  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most common violation codes:\n",
      "  Code 55: 11817 occurrences\n",
      "  Code 47: 5554 occurrences\n",
      "  Code 49: 4504 occurrences\n",
      "  Code 10: 3970 occurrences\n",
      "  Code 51: 3469 occurrences\n",
      "  Code 56: 3252 occurrences\n",
      "  Code 38: 3207 occurrences\n",
      "  Code 3: 3089 occurrences\n",
      "  Code None: 3008 occurrences\n",
      "  Code 2: 2965 occurrences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_cleaned_9 =  cleaner_9_tokenize_violations(df_cleaned_8, logger=logger)\n",
    "#df_cleaned_9.select(\"violations\").filter(pl.col(\"violations\").str.len_chars() > 10).head(5)\n",
    "# # Show full text for a few sample violations\n",
    "# sample_violations = (\n",
    "#     df_cleaned_9\n",
    "#     .select(\"violations\")\n",
    "#     .filter(pl.col(\"violations\").is_not_null() & (pl.col(\"violations\").str.len_chars() > 10))\n",
    "#     .limit(10)\n",
    "#     .to_series()\n",
    "#     .to_list()\n",
    "# )\n",
    "\n",
    "# print(\"\\nðŸ” Sample full violation texts:\")\n",
    "# for v in sample_violations:\n",
    "#     print(\"-\", v)\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ” 1. Check schema\n",
    "print(\"Schema:\")\n",
    "print(df_cleaned_9.schema)\n",
    "\n",
    "# ðŸ§ª 2. Sample rows\n",
    "print(\"\\nSample violations preview:\")\n",
    "display(\n",
    "    df_cleaned_9\n",
    "    .select([\"inspection_id\", \"results\", \"violation_codes\", \"violation_count\", \"hand_hygiene_flag\"])\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# ðŸ“Š 3. Count rows with hand hygiene flag\n",
    "hh_count = df_cleaned_9.filter(pl.col(\"hand_hygiene_flag\") == 1).height\n",
    "print(f\"\\nTotal inspections with hand hygiene-related violations: {hh_count}\")\n",
    "\n",
    "# ðŸ“ˆ 4. Count hand hygiene flags by result\n",
    "print(\"\\nHand hygiene violations by inspection result:\")\n",
    "display(\n",
    "    df_cleaned_9\n",
    "    .group_by(\"results\")\n",
    "    .agg(pl.col(\"hand_hygiene_flag\").sum().alias(\"hand_hygiene_count\"))\n",
    "    .sort(\"hand_hygiene_count\", descending=True)\n",
    ")\n",
    "\n",
    "# ðŸ“Œ 5. Top 10 most common violation codes\n",
    "print(\"\\nTop 10 most common violation codes:\")\n",
    "violation_lists = df_cleaned_9.select(\"violation_codes\").explode(\"violation_codes\").to_series().to_list()\n",
    "top_codes = Counter(violation_lists).most_common(10)\n",
    "for code, count in top_codes:\n",
    "    print(f\"  Code {code}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29542b2c-ec4a-4bb4-bee1-6b774b0a1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unique count\n",
    "# unique_licenses = df_cleaned_2.select(pl.col(\"license_\")).n_unique()\n",
    "# print(f\"ðŸ”Ž Unique license_ count: {unique_licenses}\")\n",
    "\n",
    "# # Nulls?\n",
    "# print(\"\\nâ“ Null license_ values:\")\n",
    "# print(df_cleaned_2.filter(pl.col(\"license_\").is_null()).select(\"license_\"))\n",
    "\n",
    "# # Check for bad formats (non-digit or wrong length)\n",
    "# bad_format = df_cleaned_2.filter(~pl.col(\"license_\").str.contains(r\"^\\d+$\")).select(\"license_\").unique()\n",
    "# print(\"\\nâš ï¸ license_ values with non-digit characters or wrong format:\")\n",
    "# print(bad_format)\n",
    "\n",
    "# # Length distribution\n",
    "# length_stats = df_cleaned_2.with_columns(\n",
    "#     pl.col(\"license_\").str.len_chars().alias(\"length\")\n",
    "# ).select(\"length\").describe()\n",
    "# print(\"\\nðŸ“ license_ string length distribution:\")\n",
    "# print(length_stats)\n",
    "\n",
    "# # Sample values\n",
    "# print(\"\\nðŸŽ¯ Sample license_ values:\")\n",
    "# sample_licenses = df_cleaned_2.select(\"license_\").sample(50, with_replacement=False).to_series().to_list()\n",
    "# print(sample_licenses)\n",
    "\n",
    "# # Count how many license_ values are NOT exactly 7 characters long\n",
    "# not_7_digits = df_cleaned_2.filter(pl.col(\"license_\").str.len_chars() != 7).height\n",
    "# print(f\"â— license_ values not 7 digits: {not_7_digits}\")\n",
    "\n",
    "# sample_licenses_not_7=df_cleaned_2.filter(pl.col(\"license_\").str.len_chars() != 7).select(\"license_\").unique().to_series().to_list()\n",
    "# print(sample_licenses_not_7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "488b629e-43f8-4961-bd1f-c4d665b4d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned_2.filter(pl.col(\"license_\").str.len_chars() < 5).select(\"license_\").n_unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fa6cc7b-dde3-4fa0-b5cf-885d5fd78627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     df_cleaned_2\n",
    "#     .filter(pl.col(\"license_\").str.len_chars() < 5)\n",
    "#     .group_by(\"results\")\n",
    "#     .count()\n",
    "#     .sort(\"count\", descending=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be43784a-d6ee-4c6d-86c9-4dc2bcc3af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     df_cleaned_2\n",
    "#     .group_by([\"dba_name\", \"address\", \"license_\"])\n",
    "#     .count()\n",
    "#     .filter(pl.col(\"count\") > 1)\n",
    "#     .sort([\"dba_name\", \"address\", \"count\"], descending=[False, False, True])\n",
    "#     .to_pandas()\n",
    "# )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hygiene-ml)",
   "language": "python",
   "name": "hygiene-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
